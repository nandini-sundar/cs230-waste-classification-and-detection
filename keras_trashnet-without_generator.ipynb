{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ref: https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb\n",
    "\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.test.is_gpu_available():\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# For basic Image IO\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "#Add basic logging\n",
    "import logging\n",
    "logging.basicConfig(filename='cs230_keras_notebook.log',\n",
    "                    level=logging.DEBUG,\n",
    "                   format='%(asctime)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch, class_indices):\n",
    "    print(\"image_batch_shape {}\".format(image_batch.shape))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        label_indices = np.argmax(label_batch[n])\n",
    "        \n",
    "        #Flip the dictionary from class_indices to indices_class\n",
    "        indices_class = dict((v,k) for k, v in class_indices.items()) \n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(label_batch[n])\n",
    "        plt.title(indices_class.get(label_indices))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_grayscale(image_batch, label_batch):\n",
    "    print(\"image_batch_shape {}\".format(image_batch.shape))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(np.squeeze(image_batch[n]), cmap='gray',interpolation='none')\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This assumed that you have checked out the data repo next to the object detection repo\n",
    "# Data repo can be found over here: https://github.com/nandini-sundar/CS230-TrashNet-YOLO-Labeled\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(\"../CS230-TrashNet-YOLO-Labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['glass']\n",
      " ['metal']\n",
      " ['plastic']\n",
      " ['cardboard']\n",
      " ['trash']\n",
      " ['paper']]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "class_names_file = data_dir.joinpath(\"classes.txt\")\n",
    "class_names = pd.read_csv(class_names_file, header = None, sep='\\n', names=['classes'])\n",
    "print(class_names.values)\n",
    "n_classes = len(class_names)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "data_images_dir = data_dir.joinpath(\"Images\")\n",
    "CLASS_NAMES = np.array([item.name for item in data_images_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "\n",
    "CLASS_NAMES\n",
    "\n",
    "#Make directory to save generated images\n",
    "generated_train_images_dir = data_dir.joinpath(\"generated/train\")\n",
    "generated_validation_images_dir = data_dir.joinpath(\"generated/validation\")\n",
    "generated_test_images_dir = data_dir.joinpath(\"generated/test\")\n",
    "if not os.path.exists(generated_train_images_dir):\n",
    "    os.makedirs(generated_train_images_dir)\n",
    "    os.makedirs(generated_validation_images_dir)\n",
    "    os.makedirs(generated_test_images_dir)\n",
    "else: #Empty the directory\n",
    "    shutil.rmtree(generated_train_images_dir)\n",
    "    shutil.rmtree(generated_validation_images_dir)\n",
    "    shutil.rmtree(generated_test_images_dir)\n",
    "    \n",
    "    os.makedirs(generated_train_images_dir)\n",
    "    os.makedirs(generated_validation_images_dir)\n",
    "    os.makedirs(generated_test_images_dir)\n",
    "    \n",
    "logging.info(\"Generated train images stored at {}\".format(generated_train_images_dir))\n",
    "logging.info(\"Generated validation images stored at {}\".format(generated_validation_images_dir))\n",
    "logging.info(\"Generated test images stored at {}\".format(generated_test_images_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input images 2527\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_images_dir.glob('*/*.jpg')))\n",
    "print(\"Total number of input images {}\".format(image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_for_generator(filename, x_col, y_col):\n",
    "    df = pd.read_csv(data_dir.joinpath(filename), names=[x_col])\n",
    "    \n",
    "    #Convert foldernames in filepaths to class names.\n",
    "    #Expects filepath in format : ./Images/paper/paper283.jpg\n",
    "    df[y_col] = df[x_col].apply(lambda x: os.path.basename(os.path.dirname(x)))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "x_col = \"filename\"\n",
    "y_col = 'class_list'\n",
    "\n",
    "train_df = get_dataframe_for_generator(filename='train.txt', x_col=x_col, y_col=y_col)\n",
    "logging.debug(\"Here are some train images \")\n",
    "logging.debug(train_df)\n",
    "\n",
    "test_df = get_dataframe_for_generator(filename='test.txt', x_col=x_col, y_col=y_col)\n",
    "logging.debug(\"Here are some test images \")\n",
    "logging.debug(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_join(s, repl):\n",
    "    splits = str.split(s, '/')\n",
    "    splits[1] = repl\n",
    "    return \"/\".join(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_path']  = train_df[x_col].str.replace(pat='.jpg', repl='.txt')\n",
    "train_df['label_path'] = train_df['label_path'].apply(lambda x: split_and_join(x, 'Labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_list</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Images/paper/paper283.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper283.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Images/paper/paper297.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper297.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Images/paper/paper526.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper526.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Images/paper/paper240.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper240.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Images/paper/paper254.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper254.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>./Images/plastic/plastic405.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic405.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>./Images/plastic/plastic411.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic411.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>./Images/plastic/plastic377.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic377.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>./Images/plastic/plastic439.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic439.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>./Images/plastic/plastic388.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic388.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename class_list  \\\n",
       "0         ./Images/paper/paper283.jpg      paper   \n",
       "1         ./Images/paper/paper297.jpg      paper   \n",
       "2         ./Images/paper/paper526.jpg      paper   \n",
       "3         ./Images/paper/paper240.jpg      paper   \n",
       "4         ./Images/paper/paper254.jpg      paper   \n",
       "...                               ...        ...   \n",
       "2270  ./Images/plastic/plastic405.jpg    plastic   \n",
       "2271  ./Images/plastic/plastic411.jpg    plastic   \n",
       "2272  ./Images/plastic/plastic377.jpg    plastic   \n",
       "2273  ./Images/plastic/plastic439.jpg    plastic   \n",
       "2274  ./Images/plastic/plastic388.jpg    plastic   \n",
       "\n",
       "                           label_path  \n",
       "0         ./Labels/paper/paper283.txt  \n",
       "1         ./Labels/paper/paper297.txt  \n",
       "2         ./Labels/paper/paper526.txt  \n",
       "3         ./Labels/paper/paper240.txt  \n",
       "4         ./Labels/paper/paper254.txt  \n",
       "...                               ...  \n",
       "2270  ./Labels/plastic/plastic405.txt  \n",
       "2271  ./Labels/plastic/plastic411.txt  \n",
       "2272  ./Labels/plastic/plastic377.txt  \n",
       "2273  ./Labels/plastic/plastic439.txt  \n",
       "2274  ./Labels/plastic/plastic388.txt  \n",
       "\n",
       "[2275 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_list</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Images/paper/paper283.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper283.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.966146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Images/paper/paper297.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper297.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.916016</td>\n",
       "      <td>0.986979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Images/paper/paper526.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper526.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.981771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Images/paper/paper240.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper240.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.393555</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Images/paper/paper254.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper254.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.955729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>./Images/plastic/plastic405.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic405.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>./Images/plastic/plastic411.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic411.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>./Images/plastic/plastic377.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic377.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.490234</td>\n",
       "      <td>0.404948</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>./Images/plastic/plastic439.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic439.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>./Images/plastic/plastic388.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic388.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483398</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.940104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename class_list  \\\n",
       "0         ./Images/paper/paper283.jpg      paper   \n",
       "1         ./Images/paper/paper297.jpg      paper   \n",
       "2         ./Images/paper/paper526.jpg      paper   \n",
       "3         ./Images/paper/paper240.jpg      paper   \n",
       "4         ./Images/paper/paper254.jpg      paper   \n",
       "...                               ...        ...   \n",
       "2270  ./Images/plastic/plastic405.jpg    plastic   \n",
       "2271  ./Images/plastic/plastic411.jpg    plastic   \n",
       "2272  ./Images/plastic/plastic377.jpg    plastic   \n",
       "2273  ./Images/plastic/plastic439.jpg    plastic   \n",
       "2274  ./Images/plastic/plastic388.jpg    plastic   \n",
       "\n",
       "                           label_path  class_id         x         y         w  \\\n",
       "0         ./Labels/paper/paper283.txt         5  0.503906  0.519531  0.992188   \n",
       "1         ./Labels/paper/paper297.txt         5  0.467773  0.503906  0.916016   \n",
       "2         ./Labels/paper/paper526.txt         5  0.453125  0.503906  0.890625   \n",
       "3         ./Labels/paper/paper240.txt         5  0.393555  0.585938  0.775391   \n",
       "4         ./Labels/paper/paper254.txt         5  0.550781  0.503906  0.894531   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "2270  ./Labels/plastic/plastic405.txt         2  0.501953  0.505208  0.988281   \n",
       "2271  ./Labels/plastic/plastic411.txt         2  0.689453  0.613281  0.617188   \n",
       "2272  ./Labels/plastic/plastic377.txt         2  0.490234  0.404948  0.523438   \n",
       "2273  ./Labels/plastic/plastic439.txt         2  0.588867  0.605469  0.365234   \n",
       "2274  ./Labels/plastic/plastic388.txt         2  0.483398  0.527344  0.955078   \n",
       "\n",
       "             h  \n",
       "0     0.966146  \n",
       "1     0.986979  \n",
       "2     0.981771  \n",
       "3     0.828125  \n",
       "4     0.955729  \n",
       "...        ...  \n",
       "2270  0.989583  \n",
       "2271  0.648438  \n",
       "2272  0.695312  \n",
       "2273  0.789062  \n",
       "2274  0.940104  \n",
       "\n",
       "[2275 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df['label_path'].apply(lambda label_path : pd.read_csv(data_dir.joinpath(label_path) ))\n",
    "label_format = ['class_id', 'x', 'y', 'w', 'h']\n",
    "\n",
    "labels_list = []\n",
    "for label_file in train_df['label_path']:\n",
    "    label_file = data_dir.joinpath(label_file)\n",
    "    df_label_indiv = pd.read_csv(label_file, sep=\" \", names=label_format)\n",
    "    \n",
    "    #Keeping only first row of the dataframe for simplicity\n",
    "    df_label_indiv = df_label_indiv.head(1)\n",
    "    labels_list.append(df_label_indiv)\n",
    "\n",
    "df_label_all = pd.concat(labels_list)\n",
    "df_label_all.reset_index(drop=True, inplace=True)\n",
    "#print(df_label_all)\n",
    "\n",
    "df_label_all.index = train_df.index\n",
    "train_df_x_y = pd.concat([train_df, df_label_all], axis=1, sort=False)\n",
    "train_df_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvert(yolobox, img_width,img_height ):\n",
    "    \n",
    "    ox = float(yolobox[0])\n",
    "    oy = float(yolobox[1])\n",
    "    ow = float(yolobox[2])\n",
    "    oh = float(yolobox[3])\n",
    "    x = ox*img_width\n",
    "    y = oy*img_height\n",
    "    w = ow*img_width\n",
    "    h = oh*img_height\n",
    "    xmax = (((2*x)+w)/2)\n",
    "    xmin = xmax-w\n",
    "    ymax = (((2*y)+h)/2)\n",
    "    ymin = ymax-h\n",
    "    print(xmin, ymin, xmax, ymax)\n",
    "    return int(xmin),int(xmax),int(ymin),int(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1707 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                 validation_split=0.25)\n",
    "\n",
    "train_generator = image_generator.flow_from_dataframe(dataframe=train_df_x_y,\n",
    "                                                     directory=data_dir,\n",
    "                                                     x_col=x_col,\n",
    "                                                     y_col=label_format,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     seed=SEED,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='multi_output',\n",
    "                                                    save_to_dir=generated_train_images_dir,\n",
    "                                                     subset=\"training\",\n",
    "                                                      subdirectories=True,\n",
    "                                                    save_prefix=\"gen-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "X_data = []\n",
    "for f in train_df_x_y[x_col]:\n",
    "    f = data_dir.joinpath(f)\n",
    "    f = str(f)\n",
    "    img = cv2.imread(f)\n",
    "    X_data.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2275, 384, 512, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load output y_class_output\n",
    "class_output = train_df_x_y[label_format[0]].tolist()\n",
    "y_class_output = tf.keras.utils.to_categorical(class_output, n_classes )\n",
    "y_class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'w', 'h']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_format[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50390625, 0.51953125, 0.9921875 , 0.96614583],\n",
       "       [0.46777344, 0.50390625, 0.91601562, 0.98697917],\n",
       "       [0.453125  , 0.50390625, 0.890625  , 0.98177083],\n",
       "       ...,\n",
       "       [0.49023438, 0.40494792, 0.5234375 , 0.6953125 ],\n",
       "       [0.58886719, 0.60546875, 0.36523438, 0.7890625 ],\n",
       "       [0.48339844, 0.52734375, 0.95507812, 0.94010417]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_loc_output = train_df_x_y[label_format[1:]].values\n",
    "y_loc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(image_batch, label_batch, train_generator.class_indices)\n",
    "#TODO: Convert ONE-HOT Labels back to category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(weights='imagenet',\n",
    "                                                 include_top = False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "class_output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "#loc_output = keras.layers.Dense(4)(avg)\n",
    "model = keras.models.Model(inputs=base_model.input,\n",
    "                           outputs=class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d\n",
      "13 block2_pool\n",
      "14 batch_normalization\n",
      "15 add\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_1\n",
      "23 block3_pool\n",
      "24 batch_normalization_1\n",
      "25 add_1\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_2\n",
      "33 block4_pool\n",
      "34 batch_normalization_2\n",
      "35 add_2\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_3\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_4\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_5\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_6\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_7\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_8\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_9\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_10\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_3\n",
      "123 block13_pool\n",
      "124 batch_normalization_3\n",
      "125 add_11\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n"
     ]
    }
   ],
   "source": [
    "for index, layer in enumerate(base_model.layers):\n",
    "    print(index, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "adam = tf.keras.optimizers.Adam(lr=0.01) #Higher lerarning rate\n",
    "model.compile(adam, loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1706 samples, validate on 569 samples\n",
      "Epoch 1/2\n",
      "1706/1706 [==============================] - 67s 39ms/sample - loss: 0.8584 - accuracy: 0.7140 - val_loss: 12.3029 - val_accuracy: 0.2425\n",
      "Epoch 2/2\n",
      "1706/1706 [==============================] - 23s 13ms/sample - loss: 0.3974 - accuracy: 0.8693 - val_loss: 9.4320 - val_accuracy: 0.2425\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_data, y=y_class_output, epochs=2, \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                   validation_split=0.25,\n",
    "                   shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# history = model.fit_generator(train_generator, epochs=2, workers=8, \n",
    "#                                        steps_per_epoch=train_generator.samples // BATCH_SIZE, \n",
    "#                                        shuffle=True,\n",
    "#                             validation_data=validation_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze the layers from the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "adam = tf.keras.optimizers.Adam(lr=0.000001) #Lower the lerarning rate lerarning rate\n",
    "model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=20, workers=8, \n",
    "                                       steps_per_epoch=train_generator.samples // BATCH_SIZE, \n",
    "                                       shuffle=True,\n",
    "                              validation_data=validation_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_class = dict((v,k) for k, v in train_generator.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch, label_batch, train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
