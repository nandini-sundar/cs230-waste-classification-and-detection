{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ref: https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb\n",
    "\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.test.is_gpu_available():\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# For basic Image IO\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "#Add basic logging\n",
    "import logging\n",
    "logging.basicConfig(filename='cs230_keras_notebook.log',\n",
    "                    level=logging.DEBUG,\n",
    "                   format='%(asctime)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch, class_indices):\n",
    "    print(\"image_batch_shape {}\".format(image_batch.shape))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        label_indices = np.argmax(label_batch[n])\n",
    "        \n",
    "        #Flip the dictionary from class_indices to indices_class\n",
    "        indices_class = dict((v,k) for k, v in class_indices.items()) \n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(label_batch[n])\n",
    "        plt.title(indices_class.get(label_indices))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_grayscale(image_batch, label_batch):\n",
    "    print(\"image_batch_shape {}\".format(image_batch.shape))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(np.squeeze(image_batch[n]), cmap='gray',interpolation='none')\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This assumed that you have checked out the data repo next to the object detection repo\n",
    "# Data repo can be found over here: https://github.com/nandini-sundar/CS230-TrashNet-YOLO-Labeled\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(\"../CS230-TrashNet-YOLO-Labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['glass']\n",
      " ['metal']\n",
      " ['plastic']\n",
      " ['cardboard']\n",
      " ['trash']\n",
      " ['paper']]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "class_names_file = data_dir.joinpath(\"classes.txt\")\n",
    "class_names = pd.read_csv(class_names_file, header = None, sep='\\n', names=['classes'])\n",
    "print(class_names.values)\n",
    "n_classes = len(class_names)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "data_images_dir = data_dir.joinpath(\"Images\")\n",
    "CLASS_NAMES = np.array([item.name for item in data_images_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "\n",
    "CLASS_NAMES\n",
    "\n",
    "#Make directory to save generated images\n",
    "generated_train_images_dir = data_dir.joinpath(\"generated/train\")\n",
    "generated_validation_images_dir = data_dir.joinpath(\"generated/validation\")\n",
    "generated_test_images_dir = data_dir.joinpath(\"generated/test\")\n",
    "if not os.path.exists(generated_train_images_dir):\n",
    "    os.makedirs(generated_train_images_dir)\n",
    "    os.makedirs(generated_validation_images_dir)\n",
    "    os.makedirs(generated_test_images_dir)\n",
    "else: #Empty the directory\n",
    "    shutil.rmtree(generated_train_images_dir)\n",
    "    shutil.rmtree(generated_validation_images_dir)\n",
    "    shutil.rmtree(generated_test_images_dir)\n",
    "    \n",
    "    os.makedirs(generated_train_images_dir)\n",
    "    os.makedirs(generated_validation_images_dir)\n",
    "    os.makedirs(generated_test_images_dir)\n",
    "    \n",
    "logging.info(\"Generated train images stored at {}\".format(generated_train_images_dir))\n",
    "logging.info(\"Generated validation images stored at {}\".format(generated_validation_images_dir))\n",
    "logging.info(\"Generated test images stored at {}\".format(generated_test_images_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input images 2527\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_images_dir.glob('*/*.jpg')))\n",
    "print(\"Total number of input images {}\".format(image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_for_generator(filename, x_col, y_col):\n",
    "    df = pd.read_csv(data_dir.joinpath(filename), names=[x_col])\n",
    "    \n",
    "    #Convert foldernames in filepaths to class names.\n",
    "    #Expects filepath in format : ./Images/paper/paper283.jpg\n",
    "    df[y_col] = df[x_col].apply(lambda x: os.path.basename(os.path.dirname(x)))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "x_col = \"filename\"\n",
    "y_col = 'class_list'\n",
    "\n",
    "train_df = get_dataframe_for_generator(filename='train.txt', x_col=x_col, y_col=y_col)\n",
    "logging.debug(\"Here are some train images \")\n",
    "logging.debug(train_df)\n",
    "\n",
    "test_df = get_dataframe_for_generator(filename='test.txt', x_col=x_col, y_col=y_col)\n",
    "logging.debug(\"Here are some test images \")\n",
    "logging.debug(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Images/paper/paper283.jpg</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Images/paper/paper297.jpg</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Images/paper/paper526.jpg</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Images/paper/paper240.jpg</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Images/paper/paper254.jpg</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>./Images/plastic/plastic405.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>./Images/plastic/plastic411.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>./Images/plastic/plastic377.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>./Images/plastic/plastic439.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>./Images/plastic/plastic388.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename class_list\n",
       "0         ./Images/paper/paper283.jpg      paper\n",
       "1         ./Images/paper/paper297.jpg      paper\n",
       "2         ./Images/paper/paper526.jpg      paper\n",
       "3         ./Images/paper/paper240.jpg      paper\n",
       "4         ./Images/paper/paper254.jpg      paper\n",
       "...                               ...        ...\n",
       "2270  ./Images/plastic/plastic405.jpg    plastic\n",
       "2271  ./Images/plastic/plastic411.jpg    plastic\n",
       "2272  ./Images/plastic/plastic377.jpg    plastic\n",
       "2273  ./Images/plastic/plastic439.jpg    plastic\n",
       "2274  ./Images/plastic/plastic388.jpg    plastic\n",
       "\n",
       "[2275 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [., Images, paper, paper283.jpg]\n",
       "1           [., Images, paper, paper297.jpg]\n",
       "2           [., Images, paper, paper526.jpg]\n",
       "3           [., Images, paper, paper240.jpg]\n",
       "4           [., Images, paper, paper254.jpg]\n",
       "                        ...                 \n",
       "2270    [., Images, plastic, plastic405.jpg]\n",
       "2271    [., Images, plastic, plastic411.jpg]\n",
       "2272    [., Images, plastic, plastic377.jpg]\n",
       "2273    [., Images, plastic, plastic439.jpg]\n",
       "2274    [., Images, plastic, plastic388.jpg]\n",
       "Name: filename, Length: 2275, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[x_col].str.split(pat='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_join(s, repl):\n",
    "    splits = str.split(s, '/')\n",
    "    splits[1] = repl\n",
    "    return \"/\".join(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_path']  = train_df[x_col].str.replace(pat='.jpg', repl='.txt')\n",
    "train_df['label_path'] = train_df['label_path'].apply(lambda x: split_and_join(x, 'Labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_list</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Images/paper/paper283.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper283.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Images/paper/paper297.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper297.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Images/paper/paper526.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper526.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Images/paper/paper240.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper240.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Images/paper/paper254.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper254.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>./Images/plastic/plastic405.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic405.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>./Images/plastic/plastic411.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic411.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>./Images/plastic/plastic377.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic377.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>./Images/plastic/plastic439.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic439.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>./Images/plastic/plastic388.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic388.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename class_list  \\\n",
       "0         ./Images/paper/paper283.jpg      paper   \n",
       "1         ./Images/paper/paper297.jpg      paper   \n",
       "2         ./Images/paper/paper526.jpg      paper   \n",
       "3         ./Images/paper/paper240.jpg      paper   \n",
       "4         ./Images/paper/paper254.jpg      paper   \n",
       "...                               ...        ...   \n",
       "2270  ./Images/plastic/plastic405.jpg    plastic   \n",
       "2271  ./Images/plastic/plastic411.jpg    plastic   \n",
       "2272  ./Images/plastic/plastic377.jpg    plastic   \n",
       "2273  ./Images/plastic/plastic439.jpg    plastic   \n",
       "2274  ./Images/plastic/plastic388.jpg    plastic   \n",
       "\n",
       "                           label_path  \n",
       "0         ./Labels/paper/paper283.txt  \n",
       "1         ./Labels/paper/paper297.txt  \n",
       "2         ./Labels/paper/paper526.txt  \n",
       "3         ./Labels/paper/paper240.txt  \n",
       "4         ./Labels/paper/paper254.txt  \n",
       "...                               ...  \n",
       "2270  ./Labels/plastic/plastic405.txt  \n",
       "2271  ./Labels/plastic/plastic411.txt  \n",
       "2272  ./Labels/plastic/plastic377.txt  \n",
       "2273  ./Labels/plastic/plastic439.txt  \n",
       "2274  ./Labels/plastic/plastic388.txt  \n",
       "\n",
       "[2275 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_list</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Images/paper/paper283.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper283.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.966146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Images/paper/paper297.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper297.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.916016</td>\n",
       "      <td>0.986979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Images/paper/paper526.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper526.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.981771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Images/paper/paper240.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper240.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.393555</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Images/paper/paper254.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>./Labels/paper/paper254.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.955729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>./Images/plastic/plastic405.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic405.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>./Images/plastic/plastic411.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic411.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>./Images/plastic/plastic377.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic377.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.490234</td>\n",
       "      <td>0.404948</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>./Images/plastic/plastic439.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic439.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.588867</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>./Images/plastic/plastic388.jpg</td>\n",
       "      <td>plastic</td>\n",
       "      <td>./Labels/plastic/plastic388.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483398</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.940104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename class_list  \\\n",
       "0         ./Images/paper/paper283.jpg      paper   \n",
       "1         ./Images/paper/paper297.jpg      paper   \n",
       "2         ./Images/paper/paper526.jpg      paper   \n",
       "3         ./Images/paper/paper240.jpg      paper   \n",
       "4         ./Images/paper/paper254.jpg      paper   \n",
       "...                               ...        ...   \n",
       "2270  ./Images/plastic/plastic405.jpg    plastic   \n",
       "2271  ./Images/plastic/plastic411.jpg    plastic   \n",
       "2272  ./Images/plastic/plastic377.jpg    plastic   \n",
       "2273  ./Images/plastic/plastic439.jpg    plastic   \n",
       "2274  ./Images/plastic/plastic388.jpg    plastic   \n",
       "\n",
       "                           label_path  class_id         x         y         w  \\\n",
       "0         ./Labels/paper/paper283.txt         5  0.503906  0.519531  0.992188   \n",
       "1         ./Labels/paper/paper297.txt         5  0.467773  0.503906  0.916016   \n",
       "2         ./Labels/paper/paper526.txt         5  0.453125  0.503906  0.890625   \n",
       "3         ./Labels/paper/paper240.txt         5  0.393555  0.585938  0.775391   \n",
       "4         ./Labels/paper/paper254.txt         5  0.550781  0.503906  0.894531   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "2270  ./Labels/plastic/plastic405.txt         2  0.501953  0.505208  0.988281   \n",
       "2271  ./Labels/plastic/plastic411.txt         2  0.689453  0.613281  0.617188   \n",
       "2272  ./Labels/plastic/plastic377.txt         2  0.490234  0.404948  0.523438   \n",
       "2273  ./Labels/plastic/plastic439.txt         2  0.588867  0.605469  0.365234   \n",
       "2274  ./Labels/plastic/plastic388.txt         2  0.483398  0.527344  0.955078   \n",
       "\n",
       "             h  \n",
       "0     0.966146  \n",
       "1     0.986979  \n",
       "2     0.981771  \n",
       "3     0.828125  \n",
       "4     0.955729  \n",
       "...        ...  \n",
       "2270  0.989583  \n",
       "2271  0.648438  \n",
       "2272  0.695312  \n",
       "2273  0.789062  \n",
       "2274  0.940104  \n",
       "\n",
       "[2275 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df['label_path'].apply(lambda label_path : pd.read_csv(data_dir.joinpath(label_path) ))\n",
    "label_format = ['class_id', 'x', 'y', 'w', 'h']\n",
    "\n",
    "labels_list = []\n",
    "for label_file in train_df['label_path']:\n",
    "    label_file = data_dir.joinpath(label_file)\n",
    "    df_label_indiv = pd.read_csv(label_file, sep=\" \", names=label_format)\n",
    "    \n",
    "    #Keeping only first row of the dataframe for simplicity\n",
    "    df_label_indiv = df_label_indiv.head(1)\n",
    "    labels_list.append(df_label_indiv)\n",
    "\n",
    "df_label_all = pd.concat(labels_list)\n",
    "df_label_all.reset_index(drop=True, inplace=True)\n",
    "#print(df_label_all)\n",
    "\n",
    "df_label_all.index = train_df.index\n",
    "train_df_x_y = pd.concat([train_df, df_label_all], axis=1, sort=False)\n",
    "train_df_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvert(yolobox, img_width,img_height ):\n",
    "    \n",
    "    ox = float(yolobox[0])\n",
    "    oy = float(yolobox[1])\n",
    "    ow = float(yolobox[2])\n",
    "    oh = float(yolobox[3])\n",
    "    x = ox*img_width\n",
    "    y = oy*img_height\n",
    "    w = ow*img_width\n",
    "    h = oh*img_height\n",
    "    xmax = (((2*x)+w)/2)\n",
    "    xmin = xmax-w\n",
    "    ymax = (((2*y)+h)/2)\n",
    "    ymin = ymax-h\n",
    "    print(xmin, ymin, xmax, ymax)\n",
    "    return int(xmin),int(xmax),int(ymin),int(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1707 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                 validation_split=0.25)\n",
    "\n",
    "train_generator = image_generator.flow_from_dataframe(dataframe=train_df_x_y,\n",
    "                                                     directory=data_dir,\n",
    "                                                     x_col=x_col,\n",
    "                                                     y_col=label_format,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     seed=SEED,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='multi_output',\n",
    "                                                    save_to_dir=generated_train_images_dir,\n",
    "                                                     subset=\"training\",\n",
    "                                                      subdirectories=True,\n",
    "                                                    save_prefix=\"gen-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 568 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "validation_data_gen = image_generator.flow_from_dataframe(dataframe=train_df_x_y,\n",
    "                                                     directory=data_dir,\n",
    "                                                     x_col=x_col,\n",
    "                                                     y_col=label_format,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                    seed=SEED,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='multi_output',\n",
    "                                                    save_to_dir=generated_validation_images_dir,\n",
    "                                                     subset=\"validation\",\n",
    "                                                    save_prefix=\"gen-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#Notice that y_col = None\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                                     directory=data_dir,\n",
    "                                                     x_col=x_col,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                    seed=SEED,\n",
    "                                                   class_mode=None, \n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                    save_to_dir=generated_test_images_dir,\n",
    "                                                    save_prefix=\"gen-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, label_batch = next(train_generator)\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(label_batch[0], len(label_batch) )\n",
    "\n",
    "# train_data_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameIterator' object has no attribute 'class_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4aa20d2cf4a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#TODO: Convert ONE-HOT Labels back to category labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameIterator' object has no attribute 'class_indices'"
     ]
    }
   ],
   "source": [
    "show_batch(image_batch, label_batch, train_generator.class_indices)\n",
    "#TODO: Convert ONE-HOT Labels back to category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(weights='imagenet',\n",
    "                                                 include_top = False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "class_output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "loc_output = keras.layers.Dense(4)(avg)\n",
    "model = keras.models.Model(inputs=base_model.input,\n",
    "                           outputs=[class_output, loc_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_16\n",
      "13 block2_pool\n",
      "14 batch_normalization_16\n",
      "15 add_48\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_17\n",
      "23 block3_pool\n",
      "24 batch_normalization_17\n",
      "25 add_49\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_18\n",
      "33 block4_pool\n",
      "34 batch_normalization_18\n",
      "35 add_50\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_51\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_52\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_53\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_54\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_55\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_56\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_57\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_58\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_19\n",
      "123 block13_pool\n",
      "124 batch_normalization_19\n",
      "125 add_59\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n"
     ]
    }
   ],
   "source": [
    "for index, layer in enumerate(base_model.layers):\n",
    "    print(index, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.75"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_gen.samples/validation_data_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 5 arrays: [array([[1],\n       [2],\n       [1],\n       [0],\n       [1],\n       [2],\n       [3],\n       [4],\n       [0],\n       [1],\n       [2],\n       [0],\n       [0],\n       [1],\n       [4],\n       [3],\n       ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a76a9d496975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                        \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                             validation_data=validation_data_gen)\n\u001b[0m",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    251\u001b[0m   x, y, sample_weights = model._standardize_user_data(\n\u001b[1;32m    252\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    254\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;31m# If `model._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2517\u001b[0m           \u001b[0mshapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/cs230/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    529\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 5 arrays: [array([[1],\n       [2],\n       [1],\n       [0],\n       [1],\n       [2],\n       [3],\n       [4],\n       [0],\n       [1],\n       [2],\n       [0],\n       [0],\n       [1],\n       [4],\n       [3],\n       ..."
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "adam = tf.keras.optimizers.Adam(lr=0.01) #Higher lerarning rate\n",
    "model.compile(adam, loss=['sparse_categorical_crossentropy', 'mse'], metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=2, workers=8, \n",
    "                                       steps_per_epoch=train_generator.samples // BATCH_SIZE, \n",
    "                                       shuffle=True,\n",
    "                            validation_data=validation_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze the layers from the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "adam = tf.keras.optimizers.Adam(lr=0.000001) #Lower the lerarning rate lerarning rate\n",
    "model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=20, workers=8, \n",
    "                                       steps_per_epoch=train_generator.samples // BATCH_SIZE, \n",
    "                                       shuffle=True,\n",
    "                              validation_data=validation_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_class = dict((v,k) for k, v in train_generator.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch, label_batch, train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
